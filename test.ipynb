{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "127c7dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.utils import *\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b338293",
   "metadata": {},
   "source": [
    "### íŒŒì¼ ë¶„ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e1c1619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ í˜ì´ì§€ ìˆ˜: 9\n",
      "./test/seq2seq\n",
      "ë¶„í•  PDF ìƒì„±: ./test/seq2seq_0000_0004.pdf\n",
      "./test/seq2seq\n",
      "ë¶„í•  PDF ìƒì„±: ./test/seq2seq_0005_0008.pdf\n"
     ]
    }
   ],
   "source": [
    "filepath = \"./test/seq2seq.pdf\"\n",
    "\n",
    "file_paths = split_pdf(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033da952",
   "metadata": {},
   "source": [
    "### upstageì—ì„œ ë°ì´í„° íŒŒì‹±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03bc73de",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_file_path = upstage_layout_analysis(file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bf0b558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./test/seq2seq_0000_0004.json', './test/seq2seq_0005_0008.json']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# analysis_file_path = ['./test/hana_0000_0004.json', './test/hana_0005_0008.json']\n",
    "analysis_file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ac87a3",
   "metadata": {},
   "source": [
    "### ê° íŒŒì¼ ë¶„ë¦¬í•˜ì—¬ ì €ì¥\n",
    "- page ë²ˆí˜¸ ì¡°ì •\n",
    "- id ì¡°ì •\n",
    "- html id tag ì¡°ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be9c6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./test/seq2seq\n",
      "0\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "element_content = []\n",
    "output_file_basename = os.path.splitext(filepath)[0]\n",
    "print(output_file_basename)\n",
    "page_range = 5\n",
    "last_number = 0\n",
    "for i, path in enumerate(sorted(analysis_file_path)):\n",
    "\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "        # íŒŒì¼ ë‚´ìš©ì„ íŒŒì´ì¬ ê°ì²´ë¡œ ë³€í™˜\n",
    "        data = json.load(file)  # ë³´í†µ JSON ë°°ì—´ì´ë©´ list íƒ€ì…ì´ ë¨\n",
    "        html_str = data[\"content\"][\"html\"]\n",
    "\n",
    "        change_page = page_range * i\n",
    "        print(last_number)\n",
    "        for j, element in enumerate(data[\"elements\"]):\n",
    "            element[\"id\"] = last_number + j\n",
    "            html_content = element[\"content\"][\"html\"]\n",
    "            soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "            tag = soup.find(attrs={\"id\": True})\n",
    "            tag[\"id\"] = last_number + j\n",
    "            # for tag in soup.find_all(attrs={\"id\": True}):\n",
    "            # # ì—¬ê¸°ì„œ id ì†ì„±ì„ ì›í•˜ëŠ” ê°’ìœ¼ë¡œ ë³€ê²½\n",
    "            #     tag['id'] = last_number+j\n",
    "\n",
    "            element[\"content\"][\"html\"] = str(tag)\n",
    "            element[\"page\"] = change_page + element[\"page\"]\n",
    "        last_number = len(data[\"elements\"])\n",
    "        element_content.extend(data[\"elements\"])\n",
    "\n",
    "\n",
    "with open(f\"{output_file_basename}_merged.json\", \"w\", encoding=\"utf-8\") as json_file:\n",
    "    json.dump(\n",
    "        element_content,\n",
    "        json_file,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36777216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./test/seq2seq'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_file_basename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5ef34d",
   "metadata": {},
   "source": [
    "### ë¶„ë¦¬í•œ íŒŒì¼ì—ì„œ ì´ë¯¸ì§€ ê°€ì ¸ì™€ì„œ ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3558f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./test/seq2seq_merged.json\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "ì´ë¯¸ì§€ íƒœê·¸ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "Saved image: ./test/seq2seq/image_12.png\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "ì´ë¯¸ì§€ íƒœê·¸ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "ì´ë¯¸ì§€ íƒœê·¸ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "Saved image: ./test/seq2seq/image_68.png\n",
      "Saved image: ./test/seq2seq/image_69.png\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "ì´ë¯¸ì§€ íƒœê·¸ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "Saved image: ./test/seq2seq/image_75.png\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n",
      "base64_encoding params ì—†ìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import base64\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "input_json_path = f\"{output_file_basename}_merged.json\"  # JSON íŒŒì¼ ê²½ë¡œ\n",
    "output_dir = output_file_basename  # ì´ë¯¸ì§€ ì €ì¥ í´ë”\n",
    "print(input_json_path)\n",
    "# ì €ì¥ í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "with open(input_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)  # JSON ë°°ì—´ ë°ì´í„° ë¡œë“œ\n",
    "\n",
    "arr = []\n",
    "for idx, item in enumerate(data):\n",
    "    _dict = dict()\n",
    "    if \"base64_encoding\" in item:\n",
    "        _dict = {\"base64_encoding\": item[\"base64_encoding\"]}\n",
    "        html_str = item[\"content\"][\"html\"]\n",
    "        soup = BeautifulSoup(html_str, \"html.parser\")\n",
    "        img_tags = soup.find_all(\"img\")\n",
    "        if img_tags:\n",
    "            base64_str = item[\"base64_encoding\"]\n",
    "            # base64 ë¬¸ìì—´ ë””ì½”ë”©\n",
    "            image_data = base64.b64decode(base64_str)\n",
    "            image_path = os.path.join(f\"{output_dir}/image_{idx}.png\")\n",
    "            for img_tag in soup.find_all(\"img\"):\n",
    "                # ê¸°ì¡´ ì†ì„± ëª¨ë‘ ì œê±°\n",
    "                img_tag.attrs.clear()\n",
    "                # ì›í•˜ëŠ” í…ìŠ¤íŠ¸ë¥¼ src ì†ì„±ì— ë„£ê¸°\n",
    "                img_tag[\"src\"] = image_path\n",
    "            # ì´ë¯¸ì§€ íŒŒì¼ ì €ì¥\n",
    "            _dict[\"content_text\"] = str(img_tag)\n",
    "            with open(f\"{image_path}\", \"wb\") as img_file:\n",
    "                img_file.write(image_data)\n",
    "            print(f\"Saved image: {image_path}\")\n",
    "        else:\n",
    "            _dict[\"content_text\"] = item[\"content\"][\"html\"]\n",
    "            print(\"ì´ë¯¸ì§€ íƒœê·¸ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    else:\n",
    "        _dict[\"content_text\"] = item[\"content\"][\"html\"]\n",
    "        print(\"base64_encoding params ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    _dict[\"metadata\"] = {\"id\": item[\"id\"], \"page\": item[\"page\"]}\n",
    "    arr.append(_dict)\n",
    "\n",
    "with open(f\"{output_file_basename}_merged_1.json\", \"w\", encoding=\"utf-8\") as json_file:\n",
    "    json.dump(\n",
    "        arr,\n",
    "        json_file,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8384eb21",
   "metadata": {},
   "source": [
    "### content_text ì—ì„œ html íƒœê·¸ ê°€ì ¸ì™€ tagì— img ì¡´ì¬í•˜ëŠ” ê²½ìš° ëª¨ì•„ì„œ summary ì§„í–‰ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f334ce70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./test/seq2seq_merged_1.json\n",
      "\n",
      "        Please consider the following text contextâ€”both the preceding paragraph and the following paragraphâ€”along with the included image. \n",
      "        Based on this context, provide a simple and clear explanation of the image, suitable for someone with no prior background knowledge. \n",
      "        Use easy-to-understand language and focus on the main ideas that the image conveys in relation to the text.\n",
      "\n",
      "        [Preceding paragraph text]\n",
      "        <p data-category=\"paragraph\" id=\"11\" style=\"font-size:20px\">There have been a number of related attempts to address the general sequence to sequence learning<br/>problem with neural networks. Our approach is closely related to Kalchbrenner and Blunsom [18]<br/>who were the first to map the entire input sentence to vector, and is related to Cho et al. [5] although<br/>the latter was used only for rescoring hypotheses produced by a phrase-based system. Graves [10]<br/>introduced a novel differentiable attention mechanism that allows neural networks to focus on dif-<br/>ferent parts of their input, and an elegant variant of this idea was successfully applied to machine<br/>translation by Bahdanau et al. [2]. The Connectionist Sequence Classification is another popular<br/>technique for mapping sequences to sequences with neural networks, but it assumes a monotonic<br/>alignment between the inputs and the outputs [1 1].</p>\n",
      "        [Following paragraph text]\n",
      "        <p data-category=\"paragraph\" id=\"13\" style=\"font-size:14px\">Figure 1: Our model reads an input sentence \"ABC\" and produces \"WXYZ\" as the output sentence. The<br/>model stops making predictions after outputting the end-of-sentence token. Note that the LSTM reads the<br/>input sentence in reverse, because doing so introduces many short term dependencies in the data that make the<br/>optimization problem much easier.</p>\n",
      "\n",
      "\n",
      "        ###\n",
      "        Output Format:\n",
      "        <image>\n",
      "        <title>\n",
      "        <summary>\n",
      "        <entities> \n",
      "        <path> <img src=\"./test/seq2seq/image_12.png\"/> </path>\n",
      "        <id> 12 </id>\n",
      "        </image>\n",
      "\n",
      "\n",
      "\n",
      "        Please consider the following text contextâ€”both the preceding paragraph and the following paragraphâ€”along with the included image. \n",
      "        Based on this context, provide a simple and clear explanation of the image, suitable for someone with no prior background knowledge. \n",
      "        Use easy-to-understand language and focus on the main ideas that the image conveys in relation to the text.\n",
      "\n",
      "        [Preceding paragraph text]\n",
      "        <p data-category=\"paragraph\" id=\"67\" style=\"font-size:20px\">3.8 Model Analysis</p>\n",
      "        [Following paragraph text]\n",
      "        <img src=\"./test/seq2seq/image_69.png\"/>\n",
      "\n",
      "\n",
      "        ###\n",
      "        Output Format:\n",
      "        <image>\n",
      "        <title>\n",
      "        <summary>\n",
      "        <entities> \n",
      "        <path> <img src=\"./test/seq2seq/image_68.png\"/> </path>\n",
      "        <id> 68 </id>\n",
      "        </image>\n",
      "\n",
      "\n",
      "\n",
      "        Please consider the following text contextâ€”both the preceding paragraph and the following paragraphâ€”along with the included image. \n",
      "        Based on this context, provide a simple and clear explanation of the image, suitable for someone with no prior background knowledge. \n",
      "        Use easy-to-understand language and focus on the main ideas that the image conveys in relation to the text.\n",
      "\n",
      "        [Preceding paragraph text]\n",
      "        <img src=\"./test/seq2seq/image_68.png\"/>\n",
      "        [Following paragraph text]\n",
      "        <caption id=\"70\" style=\"font-size:16px\">Figure 2: The ï¬gure shows a 2-dimensional PCA projection of the LSTM hidden states that are obtained<br/>after processing the phrases in the ï¬gures. The phrases are clustered by meaning, which in these examples is<br/>primarily a function of word order, which would be difï¬cult to capture with a bag-of-words model. Notice that<br/>both clusters have similar internal structure.</caption>\n",
      "\n",
      "\n",
      "        ###\n",
      "        Output Format:\n",
      "        <image>\n",
      "        <title>\n",
      "        <summary>\n",
      "        <entities> \n",
      "        <path> <img src=\"./test/seq2seq/image_69.png\"/> </path>\n",
      "        <id> 69 </id>\n",
      "        </image>\n",
      "\n",
      "\n",
      "\n",
      "        Please consider the following text contextâ€”both the preceding paragraph and the following paragraphâ€”along with the included image. \n",
      "        Based on this context, provide a simple and clear explanation of the image, suitable for someone with no prior background knowledge. \n",
      "        Use easy-to-understand language and focus on the main ideas that the image conveys in relation to the text.\n",
      "\n",
      "        [Preceding paragraph text]\n",
      "        <caption id=\"74\" style=\"font-size:18px\">Table 3: A few examples of long translations produced by the LSTM alongside the ground truth<br/>translations. The reader can verify that the translations are sensible using Google translate.</caption>\n",
      "        [Following paragraph text]\n",
      "        <caption id=\"76\" style=\"font-size:16px\">Figure 3: The left plot shows the performance of our system as a function of sentence length, where the<br/>x-axis corresponds to the test sentences sorted by their length and is marked by the actual sequence lengths.<br/>There is no degradation on sentences with less than 35 words, there is only a minor degradation on the longest<br/>sentences. The right plot shows the LSTMâ€™s performance on sentences with progressively more rare words,<br/>where the x-axis corresponds to the test sentences sorted by their â€œaverage word frequency rankâ€.</caption>\n",
      "\n",
      "\n",
      "        ###\n",
      "        Output Format:\n",
      "        <image>\n",
      "        <title>\n",
      "        <summary>\n",
      "        <entities> \n",
      "        <path> <img src=\"./test/seq2seq/image_75.png\"/> </path>\n",
      "        <id> 75 </id>\n",
      "        </image>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import base64\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def get_system_prompt():\n",
    "    return \"\"\"You are an expert in extracting useful information from IMAGE.\n",
    "    In particular, you specialize in analyzing papers.\n",
    "    With a given image, your task is to extract key entities, summarize them, and write useful information that can be used later for retrieval.\"\"\"\n",
    "\n",
    "\n",
    "def get_user_image_template(previous_context, next_context, image_paths, id):\n",
    "    return f\"\"\"\n",
    "        Please consider the following text contextâ€”both the preceding paragraph and the following paragraphâ€”along with the included image. \n",
    "        Based on this context, provide a simple and clear explanation of the image, suitable for someone with no prior background knowledge. \n",
    "        Use easy-to-understand language and focus on the main ideas that the image conveys in relation to the text.\n",
    "\n",
    "        [Preceding paragraph text]\n",
    "        {previous_context}\n",
    "        [Following paragraph text]\n",
    "        {next_context}\n",
    "\n",
    "\n",
    "        ###\n",
    "        Output Format:\n",
    "        <image>\n",
    "        <title>\n",
    "        <summary>\n",
    "        <entities> \n",
    "        <path> {image_paths} </path>\n",
    "        <id> {id} </id>\n",
    "        </image>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "image_urls: list[str] = []\n",
    "system_prompts: list[str] = []\n",
    "user_prompts: list[str] = []\n",
    "# ì €ì¥ í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±\n",
    "input_json_path = f\"{output_file_basename}_merged_1.json\"  # JSON íŒŒì¼ ê²½ë¡œ\n",
    "print(input_json_path)\n",
    "with open(input_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)  # JSON ë°°ì—´ ë°ì´í„° ë¡œë“œ\n",
    "\n",
    "for idx, item in enumerate(data):\n",
    "    previous_context = data[idx - 1][\"content_text\"] if idx - 1 >= 0 else None\n",
    "    next_context = data[idx + 1][\"content_text\"] if idx + 1 < len(data) else None\n",
    "    id_str = item[\"metadata\"][\"id\"]\n",
    "    html_str = item[\"content_text\"]\n",
    "    soup = BeautifulSoup(html_str, \"html.parser\")\n",
    "    img_tag = soup.find(\"img\")\n",
    "    # equation_tag = soup.find(attrs={'data-category': 'equation'})\n",
    "    if img_tag:\n",
    "        src_path = img_tag.get(\"src\")\n",
    "        image_urls.append(src_path)\n",
    "        system_prompts.append(get_system_prompt())\n",
    "        user_prompts.append(\n",
    "            get_user_image_template(previous_context, next_context, html_str, id_str)\n",
    "        )\n",
    "\n",
    "\n",
    "# print(image_urls)\n",
    "for u in user_prompts:\n",
    "    print(u + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3420378f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<image>\\n<title>Sequence-to-Sequence Model Processing an Input Sentence</title>\\n<summary>\\nThis image shows how a special type of neural network called an LSTM processes an input sentence and generates an output sentence. The input sentence consists of the letters \"A\", \"B\", and \"C\". The model reads these letters one by one and then produces an output sequence \"W\", \"X\", \"Y\", \"Z\", followed by a special end-of-sentence token (\"<EOS>\"). The arrows indicate the flow of information through the network. The model stops generating output once it produces the \"<EOS>\" token. Importantly, the model reads the input sentence in reverse order to make learning easier.\\n</summary>\\n<entities>\\n- LSTM (Long Short-Term Memory) neural network\\n- Input sentence: \"A\", \"B\", \"C\"\\n- Output sentence: \"W\", \"X\", \"Y\", \"Z\", \"<EOS>\"\\n- End-of-sentence token (\"<EOS>\")\\n- Sequence-to-sequence learning\\n</entities>\\n<path> <img src=\"./test/seq2seq/image_12.png\"/> </path>\\n<id> 12 </id>\\n</image>', '<image>\\n<title>Visualization of Relationship Sentences in a Model Analysis</title>\\n<summary>\\nThis image shows a simple graph that helps us understand how a model views different sentences about relationships between two people, Mary and John. Each point on the graph represents a sentence describing feelings or respect between Mary and John. The sentences are grouped based on their meaning and who the subject is (Mary or John). For example, sentences about Mary admiring or loving John are close together, while sentences about John admiring or loving Mary are grouped separately. This helps show how the model organizes and understands different but related sentences.\\n</summary>\\n<entities>\\n- Mary\\n- John\\n- Admire\\n- Love\\n- Respect\\n- Sentence grouping\\n- Model analysis\\n</entities>\\n<path> <img src=\"./test/seq2seq/image_68.png\"/> </path>\\n<id> 68 </id>\\n</image>', '<image>\\n<title>Visualization of Phrase Clusters Based on Meaning Using LSTM Hidden States</title>\\n<summary>\\nThis image shows how different sentences with similar meanings are grouped together based on their word order. Each point represents a sentence, and sentences that mean the same thing are placed close to each other in the graph. The graph uses a method called PCA to simplify complex data from an LSTM model, which understands the order of words. This helps show that the model can recognize meaning beyond just the words used, by paying attention to how the words are arranged.\\n</summary>\\n<entities>\\n- LSTM (Long Short-Term Memory): a type of neural network that processes sequences of words.\\n- PCA (Principal Component Analysis): a technique to reduce complex data into simpler visual forms.\\n- Phrase clusters: groups of sentences with similar meanings.\\n- Word order: the sequence in which words appear in a sentence.\\n</entities>\\n<path> <img src=\"./test/seq2seq/image_69.png\"/> </path>\\n<id> 69 </id>\\n</image>', '<image>\\n<title>Performance of LSTM Translation System by Sentence Length and Word Rarity</title>\\n<summary>\\nThis image shows two graphs comparing how well an LSTM-based translation system performs against a baseline system. The left graph measures translation quality based on sentence length, showing that the LSTM does well on short to medium sentences and only slightly worse on very long sentences. The right graph measures performance based on how rare the words in the sentences are, showing that the LSTM handles common words better but its performance drops as sentences contain rarer words. Overall, the LSTM system generally outperforms the baseline in both cases.\\n</summary>\\n<entities>\\n- LSTM (Long Short-Term Memory) translation system\\n- Baseline translation system\\n- BLEU score (a measure of translation quality)\\n- Sentence length\\n- Word frequency (rarity)\\n</entities>\\n<path> <img src=\"./test/seq2seq/image_75.png\"/> </path>\\n<id> 75 </id>\\n</image>']\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote.models import MultiModal\n",
    "\n",
    "llm = get_gpt()\n",
    "multimodal_llm = MultiModal(llm)\n",
    "answer = multimodal_llm.batch(\n",
    "    image_urls, system_prompts, user_prompts, display_image=False\n",
    ")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687d49fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id ê°’: 12\n",
      "id ê°’: 68\n",
      "id ê°’: 69\n",
      "id ê°’: 75\n"
     ]
    }
   ],
   "source": [
    "# arr = ['<image>\\n<title>ë„í‘œ 8. DDR4 ê°€ê²© ì¶”ì´</title>\\n<summary>ì´ ê·¸ë˜í”„ëŠ” 2021ë…„ 1ì›”ë¶€í„° 2025ë…„ 8ì›”ê¹Œì§€ DDR4 ë©”ëª¨ë¦¬ ê°€ê²©ì˜ ë³€ë™ ì¶”ì´ë¥¼ ë³´ì—¬ì¤€ë‹¤. ê·¸ë˜í”„ì—ëŠ” í˜„ë¬¼ ê°€ê²©ê³¼ ê³ ì • ê°€ê²© ë‘ ê°€ì§€ê°€ í‘œì‹œë˜ì–´ ìˆìœ¼ë©°, ì´ˆê¸°ì—ëŠ” ê°€ê²©ì´ ì•½ 5ë‹¬ëŸ¬ì—ì„œ ì‹œì‘í•´ ì ì°¨ í•˜ë½í•˜ì—¬ 2023ë…„ ì¤‘ë°˜ì—ëŠ” 1.5ë‹¬ëŸ¬ ê·¼ì²˜ê¹Œì§€ ë–¨ì–´ì¡Œë‹¤. ì´í›„ ê°€ê²©ì€ ë‹¤ì‹œ ìƒìŠ¹ì„¸ë¡œ ëŒì•„ì„œ 2025ë…„ 8ì›”ì—ëŠ” ì•½ 6ë‹¬ëŸ¬ì— ë„ë‹¬í•˜ëŠ” ëª¨ìŠµì„ ë‚˜íƒ€ë‚¸ë‹¤.</summary>\\n<entities>\\n- DDR4 ë©”ëª¨ë¦¬\\n- í˜„ë¬¼ ê°€ê²©\\n- ê³ ì • ê°€ê²©\\n- ê°€ê²© ë³€ë™ ì¶”ì´\\n- ê¸°ê°„: 2021ë…„ 1ì›” ~ 2025ë…„ 8ì›”\\n- ë‹¨ìœ„: ë‹¬ëŸ¬ ($)\\n</entities>\\n<path> <img src=\"./test/hana/image_43.png\"/> </path>\\n<id> 43 </id>\\n</image>', '<image>\\n<title>ë„í‘œ 9. DDR5 ê°€ê²© ì¶”ì´</title>\\n<summary>ì´ ê·¸ë˜í”„ëŠ” 2023ë…„ 1ì›”ë¶€í„° 7ì›”ê¹Œì§€ DDR5 ë©”ëª¨ë¦¬ ê°€ê²©ì˜ ë³€ë™ ì¶”ì´ë¥¼ ë³´ì—¬ì¤€ë‹¤. ë‘ ê°€ì§€ ê°€ê²©ì´ í‘œì‹œë˜ì–´ ìˆëŠ”ë°, í•˜ë‚˜ëŠ” í˜„ë¬¼ ê°€ê²©(ì§„í•œ ë…¹ìƒ‰ ì„ )ì´ê³  ë‹¤ë¥¸ í•˜ë‚˜ëŠ” ê³ ì • ê°€ê²©(íšŒìƒ‰ ì„ )ì´ë‹¤. ì´ˆê¸°ì—ëŠ” ê°€ê²©ì´ ì•½ 5.5ë‹¬ëŸ¬ì—ì„œ ì‹œì‘í•´ 3.8ë‹¬ëŸ¬ê¹Œì§€ í•˜ë½í–ˆë‹¤ê°€ ì´í›„ ì ì°¨ ìƒìŠ¹í•˜ì—¬ 7ë‹¬ëŸ¬ ì´ìƒìœ¼ë¡œ ì¦ê°€í•˜ëŠ” ì¶”ì„¸ë¥¼ ë³´ì¸ë‹¤. ê³ ì • ê°€ê²©ì€ í˜„ë¬¼ ê°€ê²©ë³´ë‹¤ ë‚®ê±°ë‚˜ ë¹„ìŠ·í•œ ìˆ˜ì¤€ì—ì„œ ì›€ì§ì´ë‹¤ê°€ í›„ë°˜ë¶€ì— ìƒìŠ¹í•˜ëŠ” ê²½í–¥ì„ ë‚˜íƒ€ë‚¸ë‹¤.</summary>\\n<entities>DDR5, ê°€ê²© ì¶”ì´, í˜„ë¬¼ ê°€ê²©, ê³ ì • ê°€ê²©, 2023ë…„ 1ì›”~7ì›”, ë‹¬ëŸ¬($)</entities>\\n<path> <img src=\"./test/hana/image_46.png\"/> </path>\\n<id>46</id>\\n</image>', '<image>\\n<title>ë„í‘œ 11. SLC 8Gb ê°€ê²© ì¶”ì´ (SLC 8Gb Price Trend)</title>\\n<summary>\\nThis line graph shows the price trend of SLC 8Gb memory chips over time, from January 2021 (21.1) to August 2025 (25.8). The vertical axis represents the price in dollars ($), ranging from 0 to 12. Two price lines are depicted: the í˜„ë¬¼ ê°€ê²© (spot price) in blue-green and the ê³ ì • ê°€ê²© (fixed price) in gray. The spot price starts around $5.5 in early 2021, rises to above $8 by early 2022, then declines and stabilizes around $6.5 until early 2024. After that, it sharply increases to nearly $10 by mid-2025 before slightly dropping. The fixed price remains relatively stable around $4.5 until late 2024, then drops sharply to below $2.5 before gradually rising again to about $3.5 by mid-2025.\\n</summary>\\n<entities>\\n- SLC 8Gb memory chip\\n- Price in USD ($)\\n- í˜„ë¬¼ ê°€ê²© (Spot Price)\\n- ê³ ì • ê°€ê²© (Fixed Price)\\n- Time period: January 2021 to August 2025\\n- Data sources: DRAMExchange, í•˜ë‚˜ì¦ê¶Œ (Hana Securities)\\n</entities>\\n<path> <img src=\"./test/hana/image_50.png\"/> </path>\\n<id> 50 </id>\\n</image>', '<image>\\n<title>í˜„ë¬¼ ê°€ê²©ê³¼ ê³ ì • ê°€ê²© ì¶”ì´ (2021ë…„ 1ì›” ~ 2025ë…„ 8ì›” ì˜ˆìƒ)</title>\\n<summary>ì´ ê·¸ë˜í”„ëŠ” 2021ë…„ 1ì›”ë¶€í„° 2025ë…„ 8ì›”ê¹Œì§€ì˜ í˜„ë¬¼ ê°€ê²©ê³¼ ê³ ì • ê°€ê²© ë³€ë™ ì¶”ì´ë¥¼ ë³´ì—¬ì¤€ë‹¤. í˜„ë¬¼ ê°€ê²©ì€ 2022ë…„ ì´ˆì— ì•½ 4ë‹¬ëŸ¬ê¹Œì§€ ìƒìŠ¹í–ˆë‹¤ê°€ ì´í›„ ì ì°¨ í•˜ë½í•˜ì—¬ 2024ë…„ ì´ˆê¹Œì§€ 2.7ë‹¬ëŸ¬ ê·¼ì²˜ì—ì„œ ìœ ì§€ë˜ë‹¤ê°€ 2025ë…„ë¶€í„° ë‹¤ì‹œ ìƒìŠ¹í•˜ëŠ” ê²½í–¥ì„ ë³´ì¸ë‹¤. ê³ ì • ê°€ê²©ì€ í˜„ë¬¼ ê°€ê²©ë³´ë‹¤ ì „ë°˜ì ìœ¼ë¡œ ë‚®ê±°ë‚˜ ë¹„ìŠ·í•œ ìˆ˜ì¤€ì„ ìœ ì§€í•˜ë©°, 2024ë…„ ì¤‘ë°˜ ì´í›„ë¶€í„°ëŠ” í˜„ë¬¼ ê°€ê²©ë³´ë‹¤ ë‚®ì€ ìˆ˜ì¤€ì—ì„œ ì™„ë§Œí•˜ê²Œ ìƒìŠ¹í•˜ëŠ” ëª¨ìŠµì„ ë‚˜íƒ€ë‚¸ë‹¤.</summary>\\n<entities>\\n- í˜„ë¬¼ ê°€ê²© (Spot Price)\\n- ê³ ì • ê°€ê²© (Fixed Price)\\n- ê¸°ê°„: 2021ë…„ 1ì›” ~ 2025ë…„ 8ì›” (ì˜ˆìƒ í¬í•¨)\\n- ë‹¨ìœ„: ë‹¬ëŸ¬($)\\n- ì¶œì²˜: DRAMExchange, í•˜ë‚˜ì¦ê¶Œ\\n</entities>\\n<path> <img src=\"./test/hana/image_52.png\"/> </path>\\n<id> 52 </id>\\n</image>', '<image>\\n<title>ë„í‘œ 12. ì£¼ìš” DRAM ì—…ì²´ë“¤ì˜ ì—°ì´ˆ ì´í›„ ì£¼ê°€ ì¶”ì´</title>\\n<summary>ì´ ê·¸ë˜í”„ëŠ” 2024ë…„ 12ì›” 31ì¼ì„ ê¸°ì¤€ìœ¼ë¡œ ì£¼ìš” DRAM ì—…ì²´ë“¤ì¸ ì‚¼ì„±ì „ì, SKí•˜ì´ë‹‰ìŠ¤, Micron, Nanyaì˜ ì£¼ê°€ ë³€ë™ ì¶”ì´ë¥¼ ë‚˜íƒ€ë‚´ê³  ìˆë‹¤. ê° ì—…ì²´ì˜ ì£¼ê°€ëŠ” 2024ë…„ 1ì›”ë¶€í„° 9ì›”ê¹Œì§€ì˜ ê¸°ê°„ ë™ì•ˆ ë³€ë™ì„ ë³´ì˜€ìœ¼ë©°, íŠ¹íˆ Nanyaì˜ ì£¼ê°€ê°€ ê°€ì¥ í° í­ìœ¼ë¡œ ìƒìŠ¹í•˜ì—¬ 210 ì´ìƒì„ ê¸°ë¡í•œ ë°˜ë©´, Micronì€ ìƒëŒ€ì ìœ¼ë¡œ ì•ˆì •ì ì¸ íë¦„ì„ ë³´ì´ë©° 100 ê·¼ì²˜ì—ì„œ ì›€ì§ì˜€ë‹¤. ì‚¼ì„±ì „ìì™€ SKí•˜ì´ë‹‰ìŠ¤ëŠ” ì¤‘ê°„ ìˆ˜ì¤€ì˜ ìƒìŠ¹ì„¸ë¥¼ ìœ ì§€í•˜ì˜€ë‹¤.</summary>\\n<entities>\\n- ì‚¼ì„±ì „ì (Samsung Electronics)\\n- SKí•˜ì´ë‹‰ìŠ¤ (SK Hynix)\\n- Micron\\n- Nanya\\n- ì£¼ê°€ ì¶”ì´ (Stock Price Trend)\\n- ê¸°ê°„: 2024ë…„ 1ì›” ~ 9ì›”\\n</entities>\\n<path> <img src=\"./test/hana/image_57.png\"/> </path>\\n<id> 57 </id>\\n</image>']\n",
    "\n",
    "# html_str = data[0]  # ë°°ì—´ì—ì„œ ì²«ë²ˆì§¸ ë¬¸ìì—´ ì¶”ì¶œ\n",
    "\n",
    "input_json_path = f\"{output_file_basename}_merged_1.json\"  # JSON íŒŒì¼ ê²½ë¡œ\n",
    "with open(input_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)  # JSON ë°°ì—´ ë°ì´í„° ë¡œë“œ\n",
    "\n",
    "for html_str in answer:\n",
    "    soup = BeautifulSoup(html_str, \"html.parser\")\n",
    "    id_tag = soup.find(\"id\")  # id íƒœê·¸ ì°¾ê¸°\n",
    "    if id_tag:\n",
    "        id_value = id_tag.text.strip()  # í…ìŠ¤íŠ¸ ì¶”ì¶œ í›„ ê³µë°± ì œê±°\n",
    "        # data[id_value]['content_text'] = html_str\n",
    "        data[int(id_value)][\"content_text\"] = html_str\n",
    "        print(\"id ê°’:\", id_value)\n",
    "    else:\n",
    "        print(\"id íƒœê·¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "with open(f\"{output_file_basename}_merged_2.json\", \"w\", encoding=\"utf-8\") as json_file:\n",
    "    json.dump(\n",
    "        data,\n",
    "        json_file,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afab9d05",
   "metadata": {},
   "source": [
    "### ë°©ì •ì‹ ì„¤ëª… ì¶”ê°€ ë¡œì§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e65bb4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        You are an AI assistant who analyzes formulas written in LaTeX format in the paper.\n",
      "        Explain the given equation easily with an appropriate example so that even a 5-year-old can understand it.\n",
      "        Explain the equation so that it can be understood without the equation by sufficiently solving it.\n",
      "\n",
      "        [Preceding paragraph text]\n",
      "        <p data-category=\"paragraph\" id=\"21\" style=\"font-size:14px\">The Recurrent Neural Network (RNN) [31, 28] is a natural generalization of feedforward neural<br/>networks to sequences. Given a sequence of inputs (x1, . Â· .,XT), a standard RNN computes a<br/>sequence of outputs (y1,Â· Â· . , YT) by iterating the following equation:</p>\n",
      "\n",
      "        [Equation]\n",
      "        $$\\begin{array}{l l l}{{h_{t}}}&{{=}}&{{\\mathrm{sigm}\\left(W^{\\mathrm{hx}}x_{t}+W^{\\mathrm{hh}}h_{t-1}\\right)}}\\\\ {{y_{t}}}&{{=}}&{{W^{\\mathrm{yh}}h_{t}}}\\end{array}$$\n",
      "\n",
      "        [Following paragraph text]\n",
      "        <p data-category=\"paragraph\" id=\"23\" style=\"font-size:14px\">The RNN can easily map sequences to sequences whenever the alignment between the inputs the<br/>outputs is known ahead of time. However, it is not clear how to apply an RNN to problems whose<br/>input and the output sequences have different lengths with complicated and non-monotonic relation-<br/>ships.</p>\n",
      "\n",
      "\n",
      "        # Output Format:\n",
      "        <title>\n",
      "        <explain>\n",
      "        <examples> \n",
      "        <id>22</id>\n",
      "\n",
      "\n",
      "\n",
      "        You are an AI assistant who analyzes formulas written in LaTeX format in the paper.\n",
      "        Explain the given equation easily with an appropriate example so that even a 5-year-old can understand it.\n",
      "        Explain the equation so that it can be understood without the equation by sufficiently solving it.\n",
      "\n",
      "        [Preceding paragraph text]\n",
      "        <p data-category=\"paragraph\" id=\"25\" style=\"font-size:14px\">The goal of the LSTM is to estimate the conditional probability p(y1, . : , YT' x1,Â·Â·Â·, xT) where<br/>(x1, Â· Â· Â· , xT) is an input sequence and Y1, Â· Â· Â· , YT' is its corresponding output sequence whose length<br/>T' may differ from T. The LSTM computes this conditional probability by first obtaining the fixed-<br/>dimensional representation v of the input sequence (x1,.. Â· , xT) given by the last hidden state of the<br/>LSTM, and then computing the probability of y1, Â· Â· Â· , YT' with a standard LSTM-LM formulation<br/>whose initial hidden state is set to the representation v of x1, Â· Â· Â· , XT:</p>\n",
      "\n",
      "        [Equation]\n",
      "        $$p(y_{1},\\cdot\\cdot\\cdot,y_{T^{\\prime}}|x_{1},\\cdot\\cdot\\cdot,x_{T})=\\prod_{t=1}^{T^{\\prime}}p(y_{t}|v,y_{1},\\cdot\\cdot\\cdot,y_{t-1})$$\n",
      "\n",
      "        [Following paragraph text]\n",
      "        <caption id=\"27\" style=\"font-size:20px\">(1)</caption>\n",
      "\n",
      "\n",
      "        # Output Format:\n",
      "        <title>\n",
      "        <explain>\n",
      "        <examples> \n",
      "        <id>26</id>\n",
      "\n",
      "\n",
      "\n",
      "        You are an AI assistant who analyzes formulas written in LaTeX format in the paper.\n",
      "        Explain the given equation easily with an appropriate example so that even a 5-year-old can understand it.\n",
      "        Explain the equation so that it can be understood without the equation by sufficiently solving it.\n",
      "\n",
      "        [Preceding paragraph text]\n",
      "        <p data-category=\"paragraph\" id=\"37\" style=\"font-size:14px\">The core of our experiments involved training a large deep LSTM on many sentence pairs. We<br/>trained it by maximizing the log probability of a correct translation T given the source sentence S,<br/>so the training objective is</p>\n",
      "\n",
      "        [Equation]\n",
      "        $$\\textstyle{1/|{\\cal G}|}_{(T,S)\\in{\\cal S}}\\log p(T|S)$$\n",
      "\n",
      "        [Following paragraph text]\n",
      "        <p data-category=\"paragraph\" id=\"39\" style=\"font-size:16px\">where s is the training set. Once training is complete, we produce translations by finding the most<br/>likely translation according to the LSTM:</p>\n",
      "\n",
      "\n",
      "        # Output Format:\n",
      "        <title>\n",
      "        <explain>\n",
      "        <examples> \n",
      "        <id>38</id>\n",
      "\n",
      "\n",
      "\n",
      "        You are an AI assistant who analyzes formulas written in LaTeX format in the paper.\n",
      "        Explain the given equation easily with an appropriate example so that even a 5-year-old can understand it.\n",
      "        Explain the equation so that it can be understood without the equation by sufficiently solving it.\n",
      "\n",
      "        [Preceding paragraph text]\n",
      "        <p data-category=\"paragraph\" id=\"39\" style=\"font-size:16px\">where s is the training set. Once training is complete, we produce translations by finding the most<br/>likely translation according to the LSTM:</p>\n",
      "\n",
      "        [Equation]\n",
      "        $${\\hat{T}}=\\arg\\operatorname*{max}_{T}p(T|S)$$\n",
      "\n",
      "        [Following paragraph text]\n",
      "        <caption id=\"41\" style=\"font-size:20px\">(2)</caption>\n",
      "\n",
      "\n",
      "        # Output Format:\n",
      "        <title>\n",
      "        <explain>\n",
      "        <examples> \n",
      "        <id>40</id>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import base64\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def get_system_prompt():\n",
    "    return \"\"\"You are an expert in extracting useful information from IMAGE.\n",
    "    In particular, you specialize in analyzing papers.\n",
    "    With a given image, your task is to extract key entities, summarize them, and write useful information that can be used later for retrieval.\"\"\"\n",
    "\n",
    "\n",
    "def get_user_equation_template(previous_context, next_context, equation, id):\n",
    "    return f\"\"\"\n",
    "        You are an AI assistant who analyzes formulas written in LaTeX format in the paper.\n",
    "        Explain the given equation easily with an appropriate example so that even a 5-year-old can understand it.\n",
    "        Explain the equation so that it can be understood without the equation by sufficiently solving it.\n",
    "\n",
    "        [Preceding paragraph text]\n",
    "        {previous_context}\n",
    "        \n",
    "        [Equation]\n",
    "        {equation}\n",
    "\n",
    "        [Following paragraph text]\n",
    "        {next_context}\n",
    "\n",
    "        \n",
    "        # Output Format:\n",
    "        <title>\n",
    "        <explain>\n",
    "        <examples> \n",
    "        <id>{id}</id>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "system_prompts: list[str] = []\n",
    "user_prompts: list[str] = []\n",
    "# ì €ì¥ í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±\n",
    "input_json_path = f\"{output_file_basename}_merged_2.json\"  # JSON íŒŒì¼ ê²½ë¡œ\n",
    "# print(input_json_path)\n",
    "with open(input_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)  # JSON ë°°ì—´ ë°ì´í„° ë¡œë“œ\n",
    "\n",
    "for idx, item in enumerate(data):\n",
    "    previous_context = data[idx - 1][\"content_text\"] if idx - 1 >= 0 else None\n",
    "    next_context = data[idx + 1][\"content_text\"] if idx + 1 < len(data) else None\n",
    "    id_str = item[\"metadata\"][\"id\"]\n",
    "    html_str = item[\"content_text\"]\n",
    "    soup = BeautifulSoup(html_str, \"html.parser\")\n",
    "    equation_tag = soup.find(attrs={\"data-category\": \"equation\"})\n",
    "    if equation_tag:\n",
    "        system_prompts.append(get_system_prompt())\n",
    "        user_prompts.append(\n",
    "            get_user_equation_template(\n",
    "                previous_context, next_context, equation_tag.get_text(), id_str\n",
    "            )\n",
    "        )\n",
    "\n",
    "for u in user_prompts:\n",
    "    print(u + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8896212c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_messages(system_prompt, user_prompt):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_prompt,\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": user_prompt,\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "    ]\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc19dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "for system_prompt, user_prompt in zip(system_prompts, user_prompts):\n",
    "    message = create_messages(system_prompt, user_prompt)\n",
    "    messages.append(message)\n",
    "messages\n",
    "llm = get_gpt()\n",
    "response = llm.batch(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "940f3965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='<title>Understanding the Basic Recurrent Neural Network (RNN) Equation</title>\\n<explain>\\nThis equation describes how a Recurrent Neural Network (RNN) processes a sequence of inputs step-by-step to produce outputs. Imagine you have a list of things coming in one after another, like words in a sentence or notes in a song. At each step (time t), the RNN looks at the current input (xt) and also remembers what it learned from the previous step (ht-1). It combines these two pieces of information using some weights (W) and a special function called \"sigmoid\" (sigm), which helps decide how much to remember or forget. This combination creates a new \"hidden state\" (ht), which is like the RNN\\'s memory at that moment. Then, the RNN uses this hidden state to produce an output (yt) for that step. This way, the RNN can understand sequences by keeping track of what happened before while looking at the new input.\\n</explain>\\n<examples>\\nImagine you are listening to a story one word at a time. At each word, you remember what happened before and use that memory to understand the next word better. For example, if the story says \"The cat sat on the,\" you remember those words so when you hear the next word \"mat,\" you understand the full sentence. Here, the hidden state (ht) is like your memory of the story so far, and the output (yt) is your understanding or reaction to the current word.\\n</examples>\\n<id>22</id>' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 324, 'prompt_tokens': 433, 'total_tokens': 757, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_c064fdde7c', 'id': 'chatcmpl-CT1JSXXMBqLvZN8OmQILLe0bTfZOV', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--8c2ee0ee-698a-4011-a0c2-46b36776ea04-0' usage_metadata={'input_tokens': 433, 'output_tokens': 324, 'total_tokens': 757, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "content=\"<title>Understanding the Conditional Probability Equation in LSTM Sequence Modeling</title>\\n\\n<explain>\\nThis equation is about how an LSTM (a type of smart computer program) predicts a sequence of outputs (like words or actions) based on a sequence of inputs. Imagine you have a story made of pictures (inputs), and you want to tell a new story (outputs) that matches those pictures.\\n\\nThe equation says: the chance of getting the whole output story (y1 to yT') given the input story (x1 to xT) can be found by looking at each output step one by one. For each output step t, the LSTM guesses the next output y_t by considering:\\n1. The summary of the entire input story (called v),\\n2. All the outputs it has already said before (y1 to y_{t-1}).\\n\\nBy multiplying all these step-by-step guesses together, we get the chance of the full output story.\\n\\nIn simpler terms, the LSTM first reads and remembers the whole input story as a summary. Then, it tells the output story one piece at a time, always remembering what it has said before and the input summary, to make the best guess for the next piece.\\n\\n</explain>\\n\\n<examples>\\nImagine you have a box of colored blocks (inputs) arranged in a certain order: red, blue, green. You want to build a tower (outputs) that matches the colors but maybe in a different order or length.\\n\\n1. First, the LSTM looks at all the blocks and makes a mental note (v) of the colors and order.\\n2. Then, it starts building the tower one block at a time.\\n3. When choosing the first block of the tower, it uses the mental note v and no previous blocks (since it's the first).\\n4. For the second block, it uses the mental note v and the first block it already placed.\\n5. It keeps doing this until the tower is complete.\\n\\nThe equation tells us that the chance of building the entire tower is the product of the chances of placing each block correctly, given what it remembers and what it has already placed.\\n\\nThis way, the LSTM can handle situations where the number of blocks in the tower (output length) is different from the number of blocks in the box (input length).\\n</examples>\\n\\n<id>26</id>\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 482, 'prompt_tokens': 455, 'total_tokens': 937, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_c064fdde7c', 'id': 'chatcmpl-CT1JSd0hFvxUIN6wH9VUJVRe0zkl9', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--b77620d2-dbb7-4641-bc31-1c558daa19da-0' usage_metadata={'input_tokens': 455, 'output_tokens': 482, 'total_tokens': 937, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "content='<title>Training Objective for LSTM-based Translation Model</title>\\n<explain>\\nThis equation describes how the model learns to translate sentences from one language to another. Imagine you have many pairs of sentences: one in the original language (source sentence S) and one in the translated language (target sentence T). The model tries to guess the correct translation T when given the source sentence S.\\n\\nTo teach the model, we look at all these sentence pairs in our training set (denoted as ğ’®). For each pair, the model calculates the probability that it would produce the correct translation T given S, written as p(T|S). We then take the logarithm (log) of this probability to make the numbers easier to work with and sum these values for all sentence pairs.\\n\\nFinally, we average this sum by dividing by the total number of sentence pairs (|ğ’¢|). The goal during training is to adjust the model so that this average log probability is as large as possible, meaning the model becomes better at predicting correct translations.\\n\\nIn simple terms, the model learns by trying to be as confident as possible that its translations are right, across many examples.\\n</explain>\\n<examples>\\nImagine you have a box of toy blocks, each block has a picture on it in one language, and you want to find the matching block with the same picture but in another language. The model is like a smart friend who guesses which block matches. At first, your friend might guess wrong, but every time you tell them the right answer, they get better at guessing. The equation is like a score that tells your friend how good their guesses are on average, and your friend tries to get the highest score by learning from many examples.\\n</examples>\\n<id>38</id>' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 362, 'prompt_tokens': 316, 'total_tokens': 678, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_c064fdde7c', 'id': 'chatcmpl-CT1JSt3NJ3WgiPCEQs92DstjDqK6X', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--624d57a2-fe6c-4e7c-9c75-d7d38ed0e5a8-0' usage_metadata={'input_tokens': 316, 'output_tokens': 362, 'total_tokens': 678, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "content='<title>Finding the Best Translation Using Probability</title>\\n<explain>\\nThis equation is about choosing the best translation for a sentence. Imagine you have a sentence in one language (called S), and you want to find the best way to say it in another language (called T). The equation says: \"Look at all possible translations (T) and pick the one that is most likely to be correct given the original sentence (S).\" \\n\\nIn simpler words, itâ€™s like having many guesses for how to translate a sentence, and you pick the guess that the computer thinks is the best or most probable. The computer uses a special method (called LSTM) to figure out which translation makes the most sense.\\n\\nSo, instead of just picking any translation, it picks the one with the highest chance of being right.\\n</explain>\\n<examples>\\nImagine you have a box of different colored balls, and you want to pick the ball that is most likely to be your favorite color. You look at all the balls and choose the color that appears the most or seems the best choice. \\n\\nSimilarly, if you want to translate \"Hello\" into another language, the computer looks at all possible translations like \"Hola,\" \"Bonjour,\" or \"Ciao,\" and picks the one it thinks is the best fit based on what it learned before.\\n\\nSo, the computer is like a smart friend who listens to the original sentence and then picks the best way to say it in another language.\\n</examples>\\n<id>40</id>' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 307, 'prompt_tokens': 262, 'total_tokens': 569, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_c064fdde7c', 'id': 'chatcmpl-CT1JSRPTyWDhiYqHiyzd6mDkKldzJ', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--1569c9b1-9872-4ae7-81f5-ecdbf938de40-0' usage_metadata={'input_tokens': 262, 'output_tokens': 307, 'total_tokens': 569, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "for r in response:\n",
    "    print(r)\n",
    "    # print(r.content +'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea63976f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='<title>Understanding the Basic Recurrent Neural Network (RNN) Equation</title>\\n<explain>\\nThis equation describes how a Recurrent Neural Network (RNN) processes a sequence of inputs step-by-step to produce outputs. Imagine you have a list of things coming in one after another, like words in a sentence or notes in a song. At each step (time t), the RNN looks at the current input (xt) and also remembers what it learned from the previous step (ht-1). It combines these two pieces of information using some weights (W) and a special function called \"sigmoid\" (sigm), which helps decide how much to remember or forget. This combination creates a new \"hidden state\" (ht), which is like the RNN\\'s memory at that moment. Then, the RNN uses this hidden state to produce an output (yt) for that step. This way, the RNN can understand sequences by keeping track of what happened before while looking at the new input.\\n</explain>\\n<examples>\\nImagine you are listening to a story one word at a time. At each word, you remember what happened before and use that memory to understand the next word better. For example, if the story says \"The cat sat on the,\" you remember those words so when you hear the next word \"mat,\" you understand the full sentence. Here, the hidden state (ht) is like your memory of the story so far, and the output (yt) is your understanding or reaction to the current word.\\n</examples>\\n<id>22</id>' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 324, 'prompt_tokens': 433, 'total_tokens': 757, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_c064fdde7c', 'id': 'chatcmpl-CT1JSXXMBqLvZN8OmQILLe0bTfZOV', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--8c2ee0ee-698a-4011-a0c2-46b36776ea04-0' usage_metadata={'input_tokens': 433, 'output_tokens': 324, 'total_tokens': 757, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "id ê°’: 22\n",
      "content=\"<title>Understanding the Conditional Probability Equation in LSTM Sequence Modeling</title>\\n\\n<explain>\\nThis equation is about how an LSTM (a type of smart computer program) predicts a sequence of outputs (like words or actions) based on a sequence of inputs. Imagine you have a story made of pictures (inputs), and you want to tell a new story (outputs) that matches those pictures.\\n\\nThe equation says: the chance of getting the whole output story (y1 to yT') given the input story (x1 to xT) can be found by looking at each output step one by one. For each output step t, the LSTM guesses the next output y_t by considering:\\n1. The summary of the entire input story (called v),\\n2. All the outputs it has already said before (y1 to y_{t-1}).\\n\\nBy multiplying all these step-by-step guesses together, we get the chance of the full output story.\\n\\nIn simpler terms, the LSTM first reads and remembers the whole input story as a summary. Then, it tells the output story one piece at a time, always remembering what it has said before and the input summary, to make the best guess for the next piece.\\n\\n</explain>\\n\\n<examples>\\nImagine you have a box of colored blocks (inputs) arranged in a certain order: red, blue, green. You want to build a tower (outputs) that matches the colors but maybe in a different order or length.\\n\\n1. First, the LSTM looks at all the blocks and makes a mental note (v) of the colors and order.\\n2. Then, it starts building the tower one block at a time.\\n3. When choosing the first block of the tower, it uses the mental note v and no previous blocks (since it's the first).\\n4. For the second block, it uses the mental note v and the first block it already placed.\\n5. It keeps doing this until the tower is complete.\\n\\nThe equation tells us that the chance of building the entire tower is the product of the chances of placing each block correctly, given what it remembers and what it has already placed.\\n\\nThis way, the LSTM can handle situations where the number of blocks in the tower (output length) is different from the number of blocks in the box (input length).\\n</examples>\\n\\n<id>26</id>\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 482, 'prompt_tokens': 455, 'total_tokens': 937, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_c064fdde7c', 'id': 'chatcmpl-CT1JSd0hFvxUIN6wH9VUJVRe0zkl9', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--b77620d2-dbb7-4641-bc31-1c558daa19da-0' usage_metadata={'input_tokens': 455, 'output_tokens': 482, 'total_tokens': 937, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "id ê°’: 26\n",
      "content='<title>Training Objective for LSTM-based Translation Model</title>\\n<explain>\\nThis equation describes how the model learns to translate sentences from one language to another. Imagine you have many pairs of sentences: one in the original language (source sentence S) and one in the translated language (target sentence T). The model tries to guess the correct translation T when given the source sentence S.\\n\\nTo teach the model, we look at all these sentence pairs in our training set (denoted as ğ’®). For each pair, the model calculates the probability that it would produce the correct translation T given S, written as p(T|S). We then take the logarithm (log) of this probability to make the numbers easier to work with and sum these values for all sentence pairs.\\n\\nFinally, we average this sum by dividing by the total number of sentence pairs (|ğ’¢|). The goal during training is to adjust the model so that this average log probability is as large as possible, meaning the model becomes better at predicting correct translations.\\n\\nIn simple terms, the model learns by trying to be as confident as possible that its translations are right, across many examples.\\n</explain>\\n<examples>\\nImagine you have a box of toy blocks, each block has a picture on it in one language, and you want to find the matching block with the same picture but in another language. The model is like a smart friend who guesses which block matches. At first, your friend might guess wrong, but every time you tell them the right answer, they get better at guessing. The equation is like a score that tells your friend how good their guesses are on average, and your friend tries to get the highest score by learning from many examples.\\n</examples>\\n<id>38</id>' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 362, 'prompt_tokens': 316, 'total_tokens': 678, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_c064fdde7c', 'id': 'chatcmpl-CT1JSt3NJ3WgiPCEQs92DstjDqK6X', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--624d57a2-fe6c-4e7c-9c75-d7d38ed0e5a8-0' usage_metadata={'input_tokens': 316, 'output_tokens': 362, 'total_tokens': 678, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "id ê°’: 38\n",
      "content='<title>Finding the Best Translation Using Probability</title>\\n<explain>\\nThis equation is about choosing the best translation for a sentence. Imagine you have a sentence in one language (called S), and you want to find the best way to say it in another language (called T). The equation says: \"Look at all possible translations (T) and pick the one that is most likely to be correct given the original sentence (S).\" \\n\\nIn simpler words, itâ€™s like having many guesses for how to translate a sentence, and you pick the guess that the computer thinks is the best or most probable. The computer uses a special method (called LSTM) to figure out which translation makes the most sense.\\n\\nSo, instead of just picking any translation, it picks the one with the highest chance of being right.\\n</explain>\\n<examples>\\nImagine you have a box of different colored balls, and you want to pick the ball that is most likely to be your favorite color. You look at all the balls and choose the color that appears the most or seems the best choice. \\n\\nSimilarly, if you want to translate \"Hello\" into another language, the computer looks at all possible translations like \"Hola,\" \"Bonjour,\" or \"Ciao,\" and picks the one it thinks is the best fit based on what it learned before.\\n\\nSo, the computer is like a smart friend who listens to the original sentence and then picks the best way to say it in another language.\\n</examples>\\n<id>40</id>' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 307, 'prompt_tokens': 262, 'total_tokens': 569, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_c064fdde7c', 'id': 'chatcmpl-CT1JSRPTyWDhiYqHiyzd6mDkKldzJ', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--1569c9b1-9872-4ae7-81f5-ecdbf938de40-0' usage_metadata={'input_tokens': 262, 'output_tokens': 307, 'total_tokens': 569, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "id ê°’: 40\n"
     ]
    }
   ],
   "source": [
    "input_json_path = f\"{output_file_basename}_merged_2.json\"  # JSON íŒŒì¼ ê²½ë¡œ\n",
    "with open(input_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)  # JSON ë°°ì—´ ë°ì´í„° ë¡œë“œ\n",
    "\n",
    "for r in response:\n",
    "    html_str = r.content\n",
    "    print(r)\n",
    "    soup = BeautifulSoup(html_str, \"html.parser\")\n",
    "    id_tag = soup.find(\"id\")  # id íƒœê·¸ ì°¾ê¸°\n",
    "    if id_tag:\n",
    "        id_value = id_tag.text.strip()  # í…ìŠ¤íŠ¸ ì¶”ì¶œ í›„ ê³µë°± ì œê±°\n",
    "        new_p = soup.new_tag(\"p\")\n",
    "        new_p.string = html_str\n",
    "        data[int(id_value)][\"content_text\"] = (\n",
    "            data[int(id_value)][\"content_text\"] + html_str\n",
    "        )\n",
    "        print(\"id ê°’:\", id_value)\n",
    "    else:\n",
    "        print(\"id íƒœê·¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "with open(\n",
    "    f\"{output_file_basename}_merged_final.json\", \"w\", encoding=\"utf-8\"\n",
    ") as json_file:\n",
    "    json.dump(\n",
    "        data,\n",
    "        json_file,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "96746e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{output_file_basename}_merged_final.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)  # JSON ë°°ì—´ ë°ì´í„° ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c588b487",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt_user_request() -> ChatPromptTemplate:\n",
    "    prompt = \"\"\"\n",
    "    You are an expert academic explainer tasked with simplifying difficult and complex research papers. Your responses must be:\n",
    "\n",
    "    - **Professional and detailed**: Use precise technical terms but always explain them thoroughly.\n",
    "    - **Clear and accessible**: Include sufficient explanations and relevant examples so that even a young child can understand.\n",
    "    - **Formatted in Markdown**: Use headings, lists, and emphasis where appropriate for readability.\n",
    "    - **Source-aware**: If the original document references specific pages or sections, always include the source page number or reference.\n",
    "    - **Image-inclusive**: If the input contains image or figure tags, display the image path or URL alongside your explanation.\n",
    "\n",
    "\n",
    "    When given a text input from a paper, first break down complex concepts step-by-step, \n",
    "    illustrate with examples or analogies, and clearly indicate the source pages if applicable. \n",
    "    Once text is entered in the paper, we first break down complex concepts step by step,\n",
    "    Explain with examples or parables and, if applicable, clearly display the source page.\n",
    "    Provides a final cohesive summary in Markdown format.\n",
    "    To represent the equation (x_1, \\\\cdots, x_T), switch to $(x_1, \\\\cdots, x_T)$ sentence and output it\n",
    "    If <img src='example'/> exists in the document you refer to, output the src path as it is\n",
    "    \n",
    "\n",
    "    ---\n",
    "\n",
    "    **Example Usage:**\n",
    "\n",
    "    Input: \"Explain the LSTM model from page 5 that includes 4 layers and GPU parallelization. Include any figures if present.\"\n",
    "\n",
    "    Output: *(Detailed, clear Markdown explanation with examples, source page 5 cited, and image paths if any).* \n",
    "    ---\n",
    "\n",
    "    Input: \"Please explain the key mechanism equation\n",
    "\"\n",
    "    Output: $(x_1, \\\\cdots, x_T)$\n",
    "    ---\n",
    "\n",
    "    **Important:**\n",
    "    Make sure to answer in Korean except for the image path and equation\n",
    " \n",
    "    \n",
    "    ** User Request:**\n",
    "    {question}\n",
    "\n",
    "    ** context :**\n",
    "    {context}    \n",
    "\"\"\"\n",
    "    return ChatPromptTemplate.from_template(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "64cce8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ì´ ë…¼ë¬¸ì´ í•´ê²°í•˜ê³ ì í•˜ëŠ” ë¬¸ì œ\n",
      "\n",
      "ì´ ë…¼ë¬¸ì€ **LSTM(Long Short-Term Memory)** ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ **ì…ë ¥ ì‹œí€€ìŠ¤** $(x_1, \\cdots, x_T)$ì— ëŒ€í•´ ê¸¸ì´ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆëŠ” **ì¶œë ¥ ì‹œí€€ìŠ¤** $(y_1, \\cdots, y_{T'})$ì˜ ì¡°ê±´ë¶€ í™•ë¥  $p(y_1, \\cdots, y_{T'} | x_1, \\cdots, x_T)$ë¥¼ ì¶”ì •í•˜ëŠ” ë¬¸ì œë¥¼ ë‹¤ë£¹ë‹ˆë‹¤. \n",
      "\n",
      "---\n",
      "\n",
      "## ë¬¸ì œì˜ í•µì‹¬\n",
      "\n",
      "- **ì…ë ¥ ì‹œí€€ìŠ¤ì™€ ì¶œë ¥ ì‹œí€€ìŠ¤ì˜ ê¸¸ì´ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ**  \n",
      "  ì˜ˆë¥¼ ë“¤ì–´, ì˜ì–´ ë¬¸ì¥(ì…ë ¥)ì´ 10ë‹¨ì–´ì´ê³ , ê·¸ì— ëŒ€ì‘í•˜ëŠ” í”„ë‘ìŠ¤ì–´ ë¬¸ì¥(ì¶œë ¥)ì´ 12ë‹¨ì–´ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  \n",
      "- **ì…ë ¥ ì‹œí€€ìŠ¤ë¥¼ ê³ ì •ëœ ì°¨ì›ì˜ ë²¡í„°ë¡œ ìš”ì•½í•˜ëŠ” ê²ƒ**  \n",
      "  LSTMì€ ì…ë ¥ ì‹œí€€ìŠ¤ ì „ì²´ë¥¼ ì½ê³ , ë§ˆì§€ë§‰ ìˆ¨ê²¨ì§„ ìƒíƒœ(hidden state)ë¥¼ í†µí•´ ì´ ì‹œí€€ìŠ¤ë¥¼ í•˜ë‚˜ì˜ ë²¡í„° $v$ë¡œ ìš”ì•½í•©ë‹ˆë‹¤.  \n",
      "- **ìš”ì•½ëœ ë²¡í„° $v$ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¶œë ¥ ì‹œí€€ìŠ¤ë¥¼ ìƒì„±**  \n",
      "  ì´ ë²¡í„° $v$ë¥¼ ì´ˆê¸° ìƒíƒœë¡œ í•˜ì—¬, LSTM ì–¸ì–´ ëª¨ë¸(LM)ì´ ì¶œë ¥ ì‹œí€€ìŠ¤ì˜ ê° ë‹¨ì–´ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì˜ˆì¸¡í•©ë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "## ë¬¸ì œë¥¼ ì‰½ê²Œ ì´í•´í•˜ê¸° ìœ„í•œ ë¹„ìœ \n",
      "\n",
      "- **ì…ë ¥ ì‹œí€€ìŠ¤**: ì—¬ëŸ¬ ì¥ì˜ ê·¸ë¦¼ì´ ìˆœì„œëŒ€ë¡œ ë†“ì—¬ ìˆëŠ” ì±…  \n",
      "- **ì¶œë ¥ ì‹œí€€ìŠ¤**: ê·¸ ê·¸ë¦¼ë“¤ì„ ë³´ê³  ìƒˆë¡­ê²Œ ì´ì•¼ê¸°ë¥¼ ë§Œë“œëŠ” ê²ƒ  \n",
      "- LSTMì€ ë¨¼ì € ì±… ì „ì²´ë¥¼ ì­‰ ì½ê³ (ì…ë ¥ ì‹œí€€ìŠ¤ ìš”ì•½), ê·¸ ë‚´ìš©ì„ ë¨¸ë¦¿ì†ì— ì €ì¥í•©ë‹ˆë‹¤(ë²¡í„° $v$).  \n",
      "- ê·¸ ë‹¤ìŒ, ë¨¸ë¦¿ì†ì— ì €ì¥í•œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ í•œ ë¬¸ì¥ì”© ì°¨ë¡€ëŒ€ë¡œ ì´ì•¼ê¸°ë¥¼ ë§Œë“¤ì–´ ë‚˜ê°‘ë‹ˆë‹¤(ì¶œë ¥ ì‹œí€€ìŠ¤ ìƒì„±).\n",
      "\n",
      "---\n",
      "\n",
      "## ìˆ˜ì‹ìœ¼ë¡œ í‘œí˜„ëœ ë¬¸ì œ (ì¶œì²˜: 3í˜ì´ì§€)\n",
      "\n",
      "$$\n",
      "p(y_{1}, \\cdots, y_{T'} | x_{1}, \\cdots, x_{T}) = \\prod_{t=1}^{T'} p(y_t | v, y_1, \\cdots, y_{t-1})\n",
      "$$\n",
      "\n",
      "- ì´ ì‹ì€ ì¶œë ¥ ì‹œí€€ìŠ¤ì˜ ê° ë‹¨ì–´ $y_t$ê°€,  \n",
      "  - ì…ë ¥ ì‹œí€€ìŠ¤ ì „ì²´ë¥¼ ìš”ì•½í•œ ë²¡í„° $v$ì™€  \n",
      "  - ì§€ê¸ˆê¹Œì§€ ìƒì„±ëœ ì¶œë ¥ ë‹¨ì–´ë“¤ $y_1, \\cdots, y_{t-1}$ì— ì¡°ê±´ë¶€ë¡œ ì˜ì¡´í•œë‹¤ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤.  \n",
      "- ì¦‰, LSTMì€ ì´ì „ì— ìƒì„±í•œ ë‹¨ì–´ë“¤ê³¼ ì…ë ¥ ì‹œí€€ìŠ¤ ìš”ì•½ ì •ë³´ë¥¼ ëª¨ë‘ ê³ ë ¤í•˜ì—¬ ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "## ìš”ì•½\n",
      "\n",
      "| ë¬¸ì œì  | ì„¤ëª… |\n",
      "|--------|-------|\n",
      "| ì…ë ¥ê³¼ ì¶œë ¥ ì‹œí€€ìŠ¤ ê¸¸ì´ ë¶ˆì¼ì¹˜ | ì…ë ¥ê³¼ ì¶œë ¥ì˜ ê¸¸ì´ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆì–´, ë‹¨ìˆœí•œ ë§¤í•‘ì´ ì–´ë ¤ì›€ |\n",
      "| ì‹œí€€ìŠ¤ ì „ì²´ë¥¼ ê³ ì •ëœ í¬ê¸°ë¡œ ìš”ì•½ | LSTMì˜ ë§ˆì§€ë§‰ ìˆ¨ê²¨ì§„ ìƒíƒœë¥¼ ì‚¬ìš©í•´ ì…ë ¥ ì‹œí€€ìŠ¤ë¥¼ í•˜ë‚˜ì˜ ë²¡í„°ë¡œ ìš”ì•½ |\n",
      "| ì¡°ê±´ë¶€ í™•ë¥  ì¶”ì • | ìš”ì•½ ë²¡í„°ì™€ ì´ì „ ì¶œë ¥ ë‹¨ì–´ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ëŠ” í™•ë¥  ëª¨ë¸ êµ¬ì¶• |\n",
      "\n",
      "ì´ ë…¼ë¬¸ì€ ìœ„ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ LSTM ê¸°ë°˜ì˜ ì‹œí€€ìŠ¤-íˆ¬-ì‹œí€€ìŠ¤(sequence-to-sequence) ëª¨ë¸ì„ ì œì•ˆí•˜ê³ , ì´ë¥¼ í†µí•´ ìì—°ì–´ ë²ˆì—­ ë“± ë‹¤ì–‘í•œ ì‹œí€€ìŠ¤ ë³€í™˜ ë¬¸ì œì— ì ìš©í•˜ê³ ì í•©ë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "# ì°¸ê³   \n",
      "- ë¬¸ì œ ì •ì˜ ë° ìˆ˜ì‹: **3í˜ì´ì§€**  \n",
      "- ìˆ˜ì‹ ì„¤ëª… ë° ì˜ˆì‹œ: 3í˜ì´ì§€ (id: 26)  \n",
      "\n",
      "---\n",
      "\n",
      "í•„ìš”í•˜ë©´ ì¶”ê°€ ì„¤ëª…ì´ë‚˜ ë‹¤ë¥¸ ë¶€ë¶„ë„ ì•Œë ¤ì£¼ì„¸ìš”!\n"
     ]
    }
   ],
   "source": [
    "user_input = \"ì´ë…¼ë¬¸ì´ í•´ê²°í•˜ê³ ìí•˜ëŠ” ë¬¸ì œê°€ë¨¸ì•¼ ?\"\n",
    "docs = []\n",
    "for d in data:\n",
    "    doc = Document(page_content=d[\"content_text\"], metadata=d[\"metadata\"])\n",
    "    docs.append(doc)\n",
    "\n",
    "faiss_retriever = get_retriever(docs)\n",
    "bm25_retriever = get_bm25_retriever(docs)\n",
    "esenmble_retriever = get_esenmble_retriever(faiss_retriever, bm25_retriever)\n",
    "rerank = get_reranker(esenmble_retriever, user_input)\n",
    "reorder_context = reorder_documents(rerank)\n",
    "prompt = get_prompt_user_request()\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "response = chain.invoke({\"question\": user_input, \"context\": reorder_context})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9abe3b",
   "metadata": {},
   "source": [
    "# ì´ ë…¼ë¬¸ì´ í•´ê²°í•˜ê³ ì í•˜ëŠ” ë¬¸ì œ\n",
    "\n",
    "ì´ ë…¼ë¬¸ì€ **LSTM(Long Short-Term Memory)** ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ **ì…ë ¥ ì‹œí€€ìŠ¤** $(x_1, \\cdots, x_T)$ì— ëŒ€í•´ ê¸¸ì´ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆëŠ” **ì¶œë ¥ ì‹œí€€ìŠ¤** $(y_1, \\cdots, y_{T'})$ì˜ ì¡°ê±´ë¶€ í™•ë¥  $p(y_1, \\cdots, y_{T'} | x_1, \\cdots, x_T)$ë¥¼ ì¶”ì •í•˜ëŠ” ë¬¸ì œë¥¼ ë‹¤ë£¹ë‹ˆë‹¤. \n",
    "\n",
    "---\n",
    "\n",
    "## ë¬¸ì œì˜ í•µì‹¬\n",
    "\n",
    "- **ì…ë ¥ ì‹œí€€ìŠ¤ì™€ ì¶œë ¥ ì‹œí€€ìŠ¤ì˜ ê¸¸ì´ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ**  \n",
    "  ì˜ˆë¥¼ ë“¤ì–´, ì˜ì–´ ë¬¸ì¥(ì…ë ¥)ì´ 10ë‹¨ì–´ì´ê³ , ê·¸ì— ëŒ€ì‘í•˜ëŠ” í”„ë‘ìŠ¤ì–´ ë¬¸ì¥(ì¶œë ¥)ì´ 12ë‹¨ì–´ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  \n",
    "- **ì…ë ¥ ì‹œí€€ìŠ¤ë¥¼ ê³ ì •ëœ ì°¨ì›ì˜ ë²¡í„°ë¡œ ìš”ì•½í•˜ëŠ” ê²ƒ**  \n",
    "  LSTMì€ ì…ë ¥ ì‹œí€€ìŠ¤ ì „ì²´ë¥¼ ì½ê³ , ë§ˆì§€ë§‰ ìˆ¨ê²¨ì§„ ìƒíƒœ(hidden state)ë¥¼ í†µí•´ ì´ ì‹œí€€ìŠ¤ë¥¼ í•˜ë‚˜ì˜ ë²¡í„° $v$ë¡œ ìš”ì•½í•©ë‹ˆë‹¤.  \n",
    "- **ìš”ì•½ëœ ë²¡í„° $v$ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¶œë ¥ ì‹œí€€ìŠ¤ë¥¼ ìƒì„±**  \n",
    "  ì´ ë²¡í„° $v$ë¥¼ ì´ˆê¸° ìƒíƒœë¡œ í•˜ì—¬, LSTM ì–¸ì–´ ëª¨ë¸(LM)ì´ ì¶œë ¥ ì‹œí€€ìŠ¤ì˜ ê° ë‹¨ì–´ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì˜ˆì¸¡í•©ë‹ˆë‹¤.\n",
    "\n",
    "---\n",
    "\n",
    "## ë¬¸ì œë¥¼ ì‰½ê²Œ ì´í•´í•˜ê¸° ìœ„í•œ ë¹„ìœ \n",
    "\n",
    "- **ì…ë ¥ ì‹œí€€ìŠ¤**: ì—¬ëŸ¬ ì¥ì˜ ê·¸ë¦¼ì´ ìˆœì„œëŒ€ë¡œ ë†“ì—¬ ìˆëŠ” ì±…  \n",
    "- **ì¶œë ¥ ì‹œí€€ìŠ¤**: ê·¸ ê·¸ë¦¼ë“¤ì„ ë³´ê³  ìƒˆë¡­ê²Œ ì´ì•¼ê¸°ë¥¼ ë§Œë“œëŠ” ê²ƒ  \n",
    "- LSTMì€ ë¨¼ì € ì±… ì „ì²´ë¥¼ ì­‰ ì½ê³ (ì…ë ¥ ì‹œí€€ìŠ¤ ìš”ì•½), ê·¸ ë‚´ìš©ì„ ë¨¸ë¦¿ì†ì— ì €ì¥í•©ë‹ˆë‹¤(ë²¡í„° $v$).  \n",
    "- ê·¸ ë‹¤ìŒ, ë¨¸ë¦¿ì†ì— ì €ì¥í•œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ í•œ ë¬¸ì¥ì”© ì°¨ë¡€ëŒ€ë¡œ ì´ì•¼ê¸°ë¥¼ ë§Œë“¤ì–´ ë‚˜ê°‘ë‹ˆë‹¤(ì¶œë ¥ ì‹œí€€ìŠ¤ ìƒì„±).\n",
    "\n",
    "---\n",
    "\n",
    "## ìˆ˜ì‹ìœ¼ë¡œ í‘œí˜„ëœ ë¬¸ì œ (ì¶œì²˜: 3í˜ì´ì§€)\n",
    "\n",
    "$$\n",
    "p(y_{1}, \\cdots, y_{T'} | x_{1}, \\cdots, x_{T}) = \\prod_{t=1}^{T'} p(y_t | v, y_1, \\cdots, y_{t-1})\n",
    "$$\n",
    "\n",
    "- ì´ ì‹ì€ ì¶œë ¥ ì‹œí€€ìŠ¤ì˜ ê° ë‹¨ì–´ $y_t$ê°€,  \n",
    "  - ì…ë ¥ ì‹œí€€ìŠ¤ ì „ì²´ë¥¼ ìš”ì•½í•œ ë²¡í„° $v$ì™€  \n",
    "  - ì§€ê¸ˆê¹Œì§€ ìƒì„±ëœ ì¶œë ¥ ë‹¨ì–´ë“¤ $y_1, \\cdots, y_{t-1}$ì— ì¡°ê±´ë¶€ë¡œ ì˜ì¡´í•œë‹¤ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤.  \n",
    "- ì¦‰, LSTMì€ ì´ì „ì— ìƒì„±í•œ ë‹¨ì–´ë“¤ê³¼ ì…ë ¥ ì‹œí€€ìŠ¤ ìš”ì•½ ì •ë³´ë¥¼ ëª¨ë‘ ê³ ë ¤í•˜ì—¬ ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤.\n",
    "\n",
    "---\n",
    "\n",
    "## ìš”ì•½\n",
    "\n",
    "| ë¬¸ì œì  | ì„¤ëª… |\n",
    "|--------|-------|\n",
    "| ì…ë ¥ê³¼ ì¶œë ¥ ì‹œí€€ìŠ¤ ê¸¸ì´ ë¶ˆì¼ì¹˜ | ì…ë ¥ê³¼ ì¶œë ¥ì˜ ê¸¸ì´ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆì–´, ë‹¨ìˆœí•œ ë§¤í•‘ì´ ì–´ë ¤ì›€ |\n",
    "| ì‹œí€€ìŠ¤ ì „ì²´ë¥¼ ê³ ì •ëœ í¬ê¸°ë¡œ ìš”ì•½ | LSTMì˜ ë§ˆì§€ë§‰ ìˆ¨ê²¨ì§„ ìƒíƒœë¥¼ ì‚¬ìš©í•´ ì…ë ¥ ì‹œí€€ìŠ¤ë¥¼ í•˜ë‚˜ì˜ ë²¡í„°ë¡œ ìš”ì•½ |\n",
    "| ì¡°ê±´ë¶€ í™•ë¥  ì¶”ì • | ìš”ì•½ ë²¡í„°ì™€ ì´ì „ ì¶œë ¥ ë‹¨ì–´ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ëŠ” í™•ë¥  ëª¨ë¸ êµ¬ì¶• |\n",
    "\n",
    "ì´ ë…¼ë¬¸ì€ ìœ„ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ LSTM ê¸°ë°˜ì˜ ì‹œí€€ìŠ¤-íˆ¬-ì‹œí€€ìŠ¤(sequence-to-sequence) ëª¨ë¸ì„ ì œì•ˆí•˜ê³ , ì´ë¥¼ í†µí•´ ìì—°ì–´ ë²ˆì—­ ë“± ë‹¤ì–‘í•œ ì‹œí€€ìŠ¤ ë³€í™˜ ë¬¸ì œì— ì ìš©í•˜ê³ ì í•©ë‹ˆë‹¤.\n",
    "\n",
    "---\n",
    "\n",
    "# ì°¸ê³   \n",
    "- ë¬¸ì œ ì •ì˜ ë° ìˆ˜ì‹: **3í˜ì´ì§€**  \n",
    "- ìˆ˜ì‹ ì„¤ëª… ë° ì˜ˆì‹œ: 3í˜ì´ì§€ (id: 26)  \n",
    "\n",
    "---\n",
    "\n",
    "í•„ìš”í•˜ë©´ ì¶”ê°€ ì„¤ëª…ì´ë‚˜ ë‹¤ë¥¸ ë¶€ë¶„ë„ ì•Œë ¤ì£¼ì„¸ìš”!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-3tRZr1Gy-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
